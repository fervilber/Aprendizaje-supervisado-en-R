<!DOCTYPE html>
<html  lang="es">

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Capítulo 9 Resumen | Aprendizaje supervisado en R</title>
  <meta name="description" content="Describimos algunos modelos de aprendizaje supervisado con R, principalmente redes bayesianas">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Capítulo 9 Resumen | Aprendizaje supervisado en R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://bookdown.org/yihui/bookdown/" />
  <meta property="og:image" content="https://bookdown.org/yihui/bookdown/imag/cover.jpg" />
  <meta property="og:description" content="Describimos algunos modelos de aprendizaje supervisado con R, principalmente redes bayesianas" />
  <meta name="github-repo" content="fervilber/redes_bayesianas_con_R" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 9 Resumen | Aprendizaje supervisado en R" />
  
  <meta name="twitter:description" content="Describimos algunos modelos de aprendizaje supervisado con R, principalmente redes bayesianas" />
  <meta name="twitter:image" content="https://bookdown.org/yihui/bookdown/imag/cover.jpg" />

<meta name="author" content="F. Villalba (fervilber@gmail.com)">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="bosques.html">
<link rel="next" href="referencias.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Aprendizaje supervisado en R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#antes-de-empezar"><i class="fa fa-check"></i><b>1.1</b> Antes de empezar</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#r"><i class="fa fa-check"></i><b>1.2</b> R</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><a href="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><i class="fa fa-check"></i><b>2</b> Preparar los datos para el modelo de aprendizaje</a><ul>
<li class="chapter" data-level="2.1" data-path="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><a href="preparar-los-datos-para-el-modelo-de-aprendizaje.html#particiones"><i class="fa fa-check"></i><b>2.1</b> Crear particiones de la muestra</a><ul>
<li class="chapter" data-level="2.1.1" data-path="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><a href="preparar-los-datos-para-el-modelo-de-aprendizaje.html#ejemplo-de-particion-a-mano"><i class="fa fa-check"></i><b>2.1.1</b> Ejemplo de partición a mano</a></li>
<li class="chapter" data-level="2.1.2" data-path="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><a href="preparar-los-datos-para-el-modelo-de-aprendizaje.html#ejemplo-de-particion-con-librarycaret"><i class="fa fa-check"></i><b>2.1.2</b> Ejemplo de partición con <code>library(caret)</code></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><a href="preparar-los-datos-para-el-modelo-de-aprendizaje.html#categorizacion-de-los-datos-origen"><i class="fa fa-check"></i><b>2.2</b> Categorización de los datos origen</a></li>
<li class="chapter" data-level="2.3" data-path="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><a href="preparar-los-datos-para-el-modelo-de-aprendizaje.html#manejo-de-na"><i class="fa fa-check"></i><b>2.3</b> Manejo de NA</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="consideraciones-previas.html"><a href="consideraciones-previas.html"><i class="fa fa-check"></i><b>3</b> Consideraciones previas</a><ul>
<li class="chapter" data-level="3.1" data-path="preparar-los-datos-para-el-modelo-de-aprendizaje.html"><a href="preparar-los-datos-para-el-modelo-de-aprendizaje.html#particiones"><i class="fa fa-check"></i><b>3.1</b> Crear particiones de la muestra</a><ul>
<li class="chapter" data-level="3.1.1" data-path="consideraciones-previas.html"><a href="consideraciones-previas.html#ejemplo-de-particion-a-mano-1"><i class="fa fa-check"></i><b>3.1.1</b> Ejemplo de partición a mano</a></li>
<li class="chapter" data-level="3.1.2" data-path="consideraciones-previas.html"><a href="consideraciones-previas.html#ejemplo-de-particion-con-librarycaret-1"><i class="fa fa-check"></i><b>3.1.2</b> Ejemplo de partición con <code>library(caret)</code></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="consideraciones-previas.html"><a href="consideraciones-previas.html#categorizacion-de-los-datos-origen-1"><i class="fa fa-check"></i><b>3.2</b> Categorización de los datos origen</a></li>
<li class="chapter" data-level="3.3" data-path="consideraciones-previas.html"><a href="consideraciones-previas.html#manejo-de-na-1"><i class="fa fa-check"></i><b>3.3</b> Manejo de NA</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="knn.html"><a href="knn.html"><i class="fa fa-check"></i><b>4</b> k-NN (k-Nearest Neighbour Classification)</a><ul>
<li class="chapter" data-level="4.1" data-path="knn.html"><a href="knn.html#consideraciones-previas-1"><i class="fa fa-check"></i><b>4.1</b> Consideraciones previas</a></li>
<li class="chapter" data-level="4.2" data-path="knn.html"><a href="knn.html#ejemplo"><i class="fa fa-check"></i><b>4.2</b> Ejemplo</a></li>
<li class="chapter" data-level="4.3" data-path="knn.html"><a href="knn.html#estandarizacion"><i class="fa fa-check"></i><b>4.3</b> Estandarización</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ingenuo.html"><a href="ingenuo.html"><i class="fa fa-check"></i><b>5</b> Naive Bayes- clasificación bayesiano ingenuo</a><ul>
<li class="chapter" data-level="5.1" data-path="ingenuo.html"><a href="ingenuo.html#crear-un-modelo-con-naivebayes"><i class="fa fa-check"></i><b>5.1</b> Crear un modelo con <code>naivebayes</code></a></li>
<li class="chapter" data-level="5.2" data-path="ingenuo.html"><a href="ingenuo.html#e1072"><i class="fa fa-check"></i><b>5.2</b> e1072</a></li>
<li class="chapter" data-level="5.3" data-path="ingenuo.html"><a href="ingenuo.html#correccion-de-laplace"><i class="fa fa-check"></i><b>5.3</b> Corrección de laplace</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>6</b> Regresión logistica binaria</a><ul>
<li class="chapter" data-level="6.1" data-path="glm.html"><a href="glm.html#construir-modelos-glm"><i class="fa fa-check"></i><b>6.1</b> Construir modelos <code>glm</code></a></li>
<li class="chapter" data-level="6.2" data-path="glm.html"><a href="glm.html#curvas-roc-y-auc"><i class="fa fa-check"></i><b>6.2</b> curvas ROC y AUC</a></li>
<li class="chapter" data-level="6.3" data-path="glm.html"><a href="glm.html#modelos-de-impacto-combinado"><i class="fa fa-check"></i><b>6.3</b> Modelos de impacto combinado</a><ul>
<li class="chapter" data-level="6.3.1" data-path="glm.html"><a href="glm.html#ejemplo-1"><i class="fa fa-check"></i><b>6.3.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="glm.html"><a href="glm.html#optimizacion-de-un-modelos-glm"><i class="fa fa-check"></i><b>6.4</b> Optimización de un modeloS <code>glm</code></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="arboles.html"><a href="arboles.html"><i class="fa fa-check"></i><b>7</b> Árboles de decisión</a><ul>
<li class="chapter" data-level="7.1" data-path="arboles.html"><a href="arboles.html#rpart"><i class="fa fa-check"></i><b>7.1</b> rpart</a><ul>
<li class="chapter" data-level="7.1.1" data-path="arboles.html"><a href="arboles.html#ejemplo-2"><i class="fa fa-check"></i><b>7.1.1</b> Ejemplo</a></li>
<li class="chapter" data-level="7.1.2" data-path="arboles.html"><a href="arboles.html#ejemplo-2-1"><i class="fa fa-check"></i><b>7.1.2</b> Ejemplo 2</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="arboles.html"><a href="arboles.html#overfitting"><i class="fa fa-check"></i><b>7.2</b> overfitting</a></li>
<li class="chapter" data-level="7.3" data-path="arboles.html"><a href="arboles.html#poda-de-los-arboles"><i class="fa fa-check"></i><b>7.3</b> Poda de los árboles</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="bosques.html"><a href="bosques.html"><i class="fa fa-check"></i><b>8</b> Bosques aleatorios de decisión</a><ul>
<li class="chapter" data-level="8.1" data-path="bosques.html"><a href="bosques.html#ejemplo-de-bosque-aleatorio"><i class="fa fa-check"></i><b>8.1</b> Ejemplo de bosque aleatorio</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="resumen.html"><a href="resumen.html"><i class="fa fa-check"></i><b>9</b> Resumen</a><ul>
<li class="chapter" data-level="9.1" data-path="resumen.html"><a href="resumen.html#crear-particiones-en-los-datos"><i class="fa fa-check"></i><b>9.1</b> Crear particiones en los datos</a></li>
<li class="chapter" data-level="9.2" data-path="resumen.html"><a href="resumen.html#tabla-resumen-de-modelos"><i class="fa fa-check"></i><b>9.2</b> Tabla resumen de modelos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Aprendizaje supervisado en R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="resumen" class="section level1">
<h1><span class="header-section-number">Capítulo 9</span> Resumen</h1>
<p>Hemos visto 5 métodos de clasificación dentro del grupo de los denominados <strong>aprendizaje supervisado</strong>. algoritmos para la generación de pronósticos a partir de datos. Cada una de estas metodologías tiene sus peculiaridades, pero tanto la forma de crear el modelo como la de llamar a la función de predicción son muy parecidas, por lo que vamos a realizar una tabla resumen en la que podamos fijarnos cada vez que estemos buscando un modelo de predicción de aprendizaje supervisado.</p>
<p>El modelo <em>knn</em> es el único que da la predicción en la misma fórmula, no en otra función. Para cada algoritmo daremos bajo su denominación, la librería en la que se carga, la formula de construcción del modelo, y la formula de predicción, así como las notas más importantes sobre su uso.</p>
<div id="crear-particiones-en-los-datos" class="section level2">
<h2><span class="header-section-number">9.1</span> Crear particiones en los datos</h2>
<ol style="list-style-type: decimal">
<li>Con el paquete <code>caret</code>
<ul>
<li>library(caret) , partición de 70/30</li>
<li><code>trainIndex=createDataPartition(misdatos$var1, p=0.70)$Resample1</code></li>
<li>Los dos conjuntos serán:</li>
<li><code>d_train=misdatos[trainIndex, ]</code> –&gt; conjunto entrenamiento</li>
<li><code>d_test= misdatos[-trainIndex, ]</code> –&gt; conjunto de test</li>
</ul></li>
<li>Con uso de sample
<ul>
<li>Contamos el número de registros de la base de datos origen y calculamos el 70% ( el % deseado) de dicha cantidad: <code>ndat&lt;-as.integer(0.7*nrow(misdatos))</code></li>
<li>Creamos una muestra aleatoria de registros: <code>reg_train &lt;- sample(nrow(misdatos), ndat)</code></li>
<li>Creamos el conjunto de registros de entrenamiento: <code>mdatos_train &lt;- misdatos[reg_train,]</code></li>
<li>Creamos el conjunto de registros de test: <code>mdatos_test &lt;- misdatos[-reg_train,]</code></li>
</ul></li>
</ol>
</div>
<div id="tabla-resumen-de-modelos" class="section level2">
<h2><span class="header-section-number">9.2</span> Tabla resumen de modelos</h2>
<ol style="list-style-type: decimal">
<li><strong>knn</strong>
<ul>
<li>library(class)</li>
<li><code>m&lt;-knn(train = tabla_train, test = tabla_test, cl = tabla_train$col_clasificadora)</code></li>
<li>el resultado de la función es el tipo de clase <code>cl</code> al que pertenecen los datos de la tabla_test</li>
<li>Para optimizar los resultados el modelo necesita estandarizar las variables normalizar distancias
<ul>
<li>scale(tabla)</li>
</ul></li>
</ul></li>
<li><strong>naivebayes</strong>
<ul>
<li>library(naivebayes)</li>
<li><code>m&lt;-naive_bayes(var_dependiente ~ var1 + var2..., data = tabla_datos, laplace = n)</code> laplace es opcional y agrega n casos para cada supuesto combinatorio.</li>
<li><code>predict(m)</code> predicción sobre toda la tabla origen</li>
<li><code>predict(m,h,type=&quot;prob&quot;)</code> siendo <code>h</code> un hecho en <code>data.frame</code>.
<ul>
<li><code>type = &quot;prob&quot;</code> muestra probabilidad de cada clase de salida, si se omite el type, el resultado es la clasificación más probable.</li>
</ul></li>
</ul></li>
<li><strong>naivebayes_e1071</strong>
<ul>
<li>library(e1071)</li>
<li><code>m&lt;-naiveBayes(var_dependiente ~ ., data = tabla_datos_train)</code></li>
<li><code>predict(m)</code> predicción sobre toda la tabla origen <code>tabla_datos_train</code>, ,<code>type=&quot;prob&quot;</code> opcional</li>
<li><code>predict(m,tabla_datos_test)</code></li>
</ul></li>
<li><strong>Regresión logistica</strong> <code>glm</code>
<ul>
<li>library(stats), cargada por defecto con R base.</li>
<li><code>m_glm&lt;-glm(y ~ x1 + x2 + x3,data = misdatos_train, family = &quot;binomial&quot;)</code></li>
<li><code>m_glm&lt;-glm(y ~ x1*x2, data = misdatos_train, family = &quot;binomial&quot;)</code> para variables con impacto combinado, efecto conjunto exponencial sobre la variable dependiente.</li>
<li>probabilidad: <code>prob &lt;- predict(m_glm, misdatos_test, type = &quot;response&quot;)</code> usar tipo response</li>
<li>umbral de predicción: <code>pred &lt;- ifelse(prob &gt; 0.50, 1, 0)</code></li>
<li><code>summary(m_glm)</code></li>
</ul></li>
<li><strong>Optimizacion de regresión logistica</strong> <code>glm</code>
<ul>
<li>Se usa para hallar el mejor modelo de pronóstico, definiendo un inicio y fin de modelos:<br />
1.Modelo sin predictores: <code>null_model &lt;- glm(var1 ~ 1, data = misdatos, family = &quot;binomial&quot;)</code> 2.Modelo completo: <code>full_model &lt;- glm(var1 ~ ., data = misdatos, family = &quot;binomial&quot;)</code>
<ol start="3" style="list-style-type: decimal">
<li>función step(): <code>step_model &lt;- step(null_model, scope = list(lower = null_model, upper = full_model), direction = &quot;forward&quot;)</code></li>
</ol></li>
<li><code>summary(step_model)</code> da el resultado de las pruebas con el mejor modelo</li>
<li>Para estimar la probabilidad: <code>step_prob &lt;- predict(step_model, type = &quot;response&quot;)</code></li>
</ul></li>
<li><strong>Árboles de decisión</strong>
<ul>
<li>los datos origen a clasificar deben ser factores o estar categorizados. No es conveniente usar datos continuos.</li>
<li><code>library(rpart)</code></li>
<li>Hay que definir una poda <code>poda&lt;-rpart.control(cp= 0.2, maxdepth = 30, minsplit = 20)</code>que limita el árbol, lo más común es usar solo cp=0.2.</li>
<li><code>m_tree&lt;-rpart(var_dependiente ~ ., data = tabla_datos_train, control = poda)</code></li>
<li><code>predict(m_tree, h,type = &quot;class&quot;)</code> predicción sobre el hecho <code>h</code></li>
<li><code>predict(m,tabla_datos_test)</code> predicción sobre los datos de test</li>
<li>Se puede dibujar el árbol con rpart.plot: <code>rpart.plot(m_tree, type = 2, clip.right.labs = FALSE,</code> <code>branch = .6,</code> <code>box.palette = c( &quot;red&quot;,&quot;green&quot;),</code><br />
<code>main = &quot;Ejemplo de arbol \n lalala&quot;)</code></li>
</ul></li>
<li><strong>Bosques aleatorios</strong>.
<ul>
<li>Los bosques son sumas de modelos de árboles. Por lo que es mejor no usar datos continuos sino categorizados.</li>
<li><code>library(randomForest)</code></li>
<li><code>m_bosque &lt;- randomForest(var_dependiente ~ ., data = tabla_datos_train[complete.cases(tabla_datos_train),], ntree = 100 )</code> Hemos excluido todos los posibles NA, pero podría hacerse previamente un <code>impute</code> de estos datos.</li>
<li><code>predict(m_bosque)</code> predicción sobre toda la tabla origen<br />
</li>
<li><code>predict(m_bosque,tabla_datos_test)</code>, predicción sobre los datos de test</li>
<li>Pintamos la evolución del modelo y vemos a partir de qué numero de arboles los resultados son homogéneos: <code>plot(m_bosque)</code></li>
</ul></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="bosques.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="referencias.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/07-bosques_aleatorios.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Aprendizaje supervisado en R.pdf", "Aprendizaje supervisado en R.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
